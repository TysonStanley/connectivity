---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

devtools::load_all("~/Dropbox/GitHub/Connectivity")
```
# connectivity

The goal of connectivity is to make the importing, cleaning, and analyzing of NIRS data recipe based. That is, we will use a simple recipe to take our individual NIRS files and make clear, concise analyses with interpretable output. Our approach uses a type of Granger-Causality approach using linear mixed effects models.

## Installation

You can install the GitHub version of `connectivity` with:

``` r
remotes::install_github("tysonstanley/connectivity")
```

## Example

The receipe is as follows:

1. Import and Clean
2. Analyze
3. Visualize

The `import_nirs()` function depends on a files structure that looks something like:

```{r, echo = FALSE, eval = FALSE}
## quick-and-dirty ersatz Unix tree command in R
## inspired by this one-liner:
## ls -R | grep ":$" | sed -e 's/:$//' -e 's/[^-][^\/]*\//--/g' -e 's/^/   /' -e 's/-/|/'
## found here (among many other places):
## http://serverfault.com/questions/143954/how-to-generate-an-ascii-representation-of-a-unix-file-hierarchy

twee <- function(path = getwd(), level = Inf) {
  
  fad <-
    list.files(path = path, recursive = TRUE,no.. = TRUE, include.dirs = TRUE)

  fad_split_up <- strsplit(fad, "/")

  too_deep <- lapply(fad_split_up, length) > level
  fad_split_up[too_deep] <- NULL
  
  jfun <- function(x) {
    n <- length(x)
    if(n > 1)
      x[n - 1] <- "|__"
    if(n > 2)
      x[1:(n - 2)] <- "   "
    x <- if(n == 1) c("-- ", x) else c("   ", x)
    x
  }
  fad_subbed_out <- lapply(fad_split_up, jfun)
  
  cat(unlist(lapply(fad_subbed_out, paste, collapse = "")), sep = "\n")
}
twee("~/Box/Stuttering Writing Group/PhoneCallsStutter/", level = 2)
```
```
-- P07
   |__ons.txt
   |__P07_brodExtract.csv
   |__P07_HBA_Probe1_Oxy.csv
   |__P07_HBA_Probe2_Oxy.csv
-- P08
   |__ons.txt
   |__P08_brodExtract.csv
   |__P08_HBA_Probe1_Oxy.csv
   |__P08_HBA_Probe2_Oxy.csv
-- P09
   |__ons.txt
   |__P09_brodExtract.csv
   |__P09_HBA_Probe1_Oxy.csv
   |__...
```   

where each participant has its own folder with the data within that folder. Other files can be within the individual folders, but the ones shown are required.

In our data (not currently provided), we have 5 regions that we are interested in that are mapped out in the `*brod.csv` files. To inform on what region goes with which channel from the Probe files, we use the import function like so:

```{r, message = FALSE, warning = FALSE}
## Superior Temporal Gyrus (STG),
## Inferior Parietal Lobule (made up of Supramarginal Gyrus and Angular Gyrus),
## Inferior frontal Gyrus (IFG),
## Supplementary Motor Association (SMA) and
## the Motor Cortex (M1)

library(connectivity)

path <- "~/Box/Stuttering Writing Group/PhoneCallsControl/"
data <- import_nirs(path,
                    stg = 22, ipl = c(39, 40), ifg = c(44, 45), sma = 6, m1 = 4)
```

The `stg = 22, ipl = c(30, 40), ...` correspond to regions (the name) and their number in the `*brod.csv` file. This creates a nested tibble called `data` that looks like this:

```{r}
data
```

The `probe_data` variable contains all the NIRS information about the corresponding participant. From here, we can run our connectivity analysis, which will run a series of linear mixed effects models. If we specify a group variable, the models will include a region by group interaction. Here, we are only going to use the "resting" task for these analyses.

```{r}
## Subset the data to just resting and assign to `rest`
rest <- data 
rest$probe_data = purrr::map(rest$probe_data, ~.x %>% filter(task == "rest"))
## Make sure `rest` still contains information on the regions in the data
attr(rest, "regions")
```


```{r}
fits <- get_connectivity(rest, covariates = c("(1 | participant)"))
fits
```

This `fits` object has all the estimates from the various models and their corresopnding p-values (based on Satterthwaite approximation to degrees of freedom). The `est` variable shows us the effect size for each variable. This effect size is the average individuals standardized coefficient (similar to a partial correlation). (Note that `lag` is the 1 lag of the outcome variable and so its effect sizes will almost always be really big).

We can visualize these results in two main ways:

1. Simple graphs highlighting the effect size
2. Brain visualization where the various regions are mapped onto a diagram of a brain

Here, we quickly show both.

#### Effect Size Graphs

```{r}
effectsize_viz(fits)
```


#### Brain Visualization

```{r}
brain_viz(fits)
```

For this brain viz, there is a built-in list of regions with corresponding `x` and `y` values that fit this diagram.

```{r}
connectivity::regions
```

However, if you want to add your own, you can. You need to make sure the names you give the regions in the `import_nirs()` function matches the names in the regions and that this `regions` data frame has the names `x`, `y`, and `region`. For example, let's say we are only interested in three of these regions now. We could use the following `regs` data frame to adjust not only what is shown but where they are shown. Importantly, the values for the `x` and `y` are bound between 0 and 10 (0 being the left/bottom and 10 being right/top) and so this example is extreme.

```{r}
regs <- tibble::tribble(
  ~x, ~y, ~region,
   1,  1,  "stg",
   5,  9,  "ipl",
   9,  1,  "ifg" 
)

brain_viz(fits, regs = regs)
```





